---
title: "GenericML blog post"
author: "Lucas Kitzmueller"
date: "10/12/2021"
output: html_document
---

This code very closely follows the example from https://github.com/mwelz/GenericML/. All credit for the implementation of the method goes to them.

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

# SET UP
#install.packages("devtools")
#devtools::install_github("mwelz/GenericML") 
#note that the package may also be available on CRAN by the time you are reading this
library(GenericML)
library(DescTools) #only used for winsorizing

# DATA GENERATION

# Set seed to make data generation reproducible
set.seed(1)

# Number of students
num.obs  <- 5000

# Number of baseline characteristics collected
num.vars <- 20

# Random treatment assignment (50% are in treatment, 50% in control)
D <- rbinom(num.obs, 1, 0.5)

# Randomly generate baseline characteristics
Z <- mvtnorm::rmvnorm(num.obs, mean = rep(0, num.vars), sigma = diag(num.vars))
colnames(Z) <- paste0("z", 1:num.vars)

# Average Treatment Effect (ATE)
ATE <- 5

# Heterogeneous Treatment Effects (HTE) 
HTE <- (abs(Z[,1])^1.1)+ ((Z[,2] * Z[,3]) / (Z[,4]+3)) + (Z[,5]+1) + (5*Z[,6]) + (Z[,7]*(2*Z[,8]+3)) + rnorm(num.obs, 0, 1)
HTE <- Winsorize(HTE-mean(HTE))

# Counterfactual outcomes
Y0 <- rnorm(num.obs, mean = 50, sd = 10)
Y1 <- Y0 + ATE + HTE

# Observed outcome
Y  <- ifelse(D == 1, Y1, Y0)

```



```{r prep_arguments, include=FALSE}

### 2. Prepare the arguments for GenericML() ----

# quantile cutoffs for the GATES grouping of the estimated CATEs
quantile.cutoffs         <- c(0.2, 0.4, 0.6, 0.8) # 20%, 40%, 60%, 80% quantiles

# Since treatment was randomized, the propensity score is constant.
learner.propensity.score <- rep(0.5,num.obs)

# specify the considered learners of the BCA and the CATE (here: elastic net, random forest, and SVM)
learners.genericML       <- c("elastic.net", "mlr3::lrn('ranger', num.trees = 100)", "mlr3::lrn('svm')")
learners.genericML       <- c("mlr3::lrn('kknn')","mlr3::lrn('svm')","mlr3::lrn('ranger', num.trees = 1000)","mlr3::lrn('cv_glmnet')","mlr3::lrn('xgboost', eval_metric = 'logloss')") 

# specify the data that shall be used for the CLAN
# here, we use all variables of Z and uniformly distributed random noise
#Z_CLAN <- cbind(Z, random = runif(num.obs))
Z_CLAN <- Z

# specify the number of splits
num.splits               <- 100

# specify if a HT transformation shall be used when estimating BLP and GATES
HT.transformation <- FALSE

# A list controlling the variables that shall be used in the matrix X1 for the BLP and GATES regressions. 
X1.variables_BLP    <- list(functions_of_Z = c("B"),
                            custom_covariates = NULL,
                            fixed_effects = NULL)
X1.variables_GATES  <- list(functions_of_Z = c("B"),
                            custom_covariates = NULL,
                            fixed_effects = NULL)

# consider differences between group K (most affected) with groups 1 and 2, respectively.
differences.control_GATES  <- list(group.to.subtract.from = "most",
                                   groups.to.be.subtracted = c(1,2))
differences.control_CLAN  <- list(group.to.subtract.from = "most",
                                  groups.to.be.subtracted = c(1,2))

# specify the significance level
significance.level       <- 0.05

# specify minimum variation of predictions before Gaussian noise with variance var(Y)/20 is added.
minimum.variation <- 1e-05

# specify which estimator of the error covariance matrix shall be used in BLP and GATES (standard OLS covariance matrix estimator here)
vcov.control_BLP   <- list(estimator = "vcovHC",
                           arguments = list(type = "const"))
vcov.control_GATES <- list(estimator = "vcovHC",
                           arguments = list(type = "const"))

# specify whether of not it should be assumed that the group variances of the most and least affected groups are equal in CLAN.
equal.group.variances_CLAN <- FALSE

# specify the proportion of samples that shall be selected in the main set
proportion.in.main.set   <- 0.5

# specify whether or not the splits and auxiliary results of the learners shall be stored
store.splits             <- FALSE
store.learners           <- FALSE

# parallelization options (currently only supported on Unix systems)
parallel  <- FALSE
num.cores <- parallel::detectCores() # maximum number
seed      <- 12345
# Note that the number of cores influences the random number stream. Thus, different choices of `num.cores` may lead to different results.
```

```{r prep_arguments, include=FALSE}

### 3. Run the GenericML() functions with these arguments ----
# runtime: ~30 seconds with R version 4.1.0 on a Dell Latitude 5300 (i5-8265U CPU @ 1.60GHz Ã— 8, 32GB RAM), running on Ubuntu 21.04. Returns a GenericML object.
genML <- GenericML(Z = Z, D = D, Y = Y,
                   learner.propensity.score = learner.propensity.score,
                   learners.genericML = learners.genericML,
                   num.splits = num.splits,
                   Z_CLAN = Z_CLAN,
                   HT.transformation = HT.transformation,
                   X1.variables_BLP = X1.variables_BLP,
                   X1.variables_GATES = X1.variables_GATES,
                   vcov.control_BLP = vcov.control_BLP,
                   vcov.control_GATES = vcov.control_GATES,
                   quantile.cutoffs = quantile.cutoffs,
                   differences.control_GATES = differences.control_GATES,
                   differences.control_CLAN = differences.control_CLAN,
                   equal.group.variances_CLAN = equal.group.variances_CLAN,
                   proportion.in.main.set = proportion.in.main.set,
                   significance.level = significance.level,
                   minimum.variation = minimum.variation,
                   parallel = parallel,
                   num.cores = num.cores,
                   seed = seed,
                   store.splits = store.splits,
                   store.learners = store.learners)
```


```{r setup, include=FALSE}
### 4. Analyze the output ----
# the line below returns the medians of the estimated  \Lambda and \bar{\Lambda}
genML$best.learners$lambda.overview

# Get best learner for CATE
genML$best.learners$best.learner.for.CATE

# Get best learner for GATES
genML$best.learners$best.learner.for.GATES

# VEIN of BLP
round(genML$VEIN$best.learners$BLP, 3)
plot(genML, type = "BLP", title = "VEIN of BLP") # plot.GenericML() method
# No indication of treatment effect heterogeneity; see beta.2 coefficient

# VEIN of GATES
genML$VEIN$best.learners$GATES
plot(genML, type = "GATES", title = "VEIN of GATES")
# No indication of heterogeneity

# VEIN of CLAN for variable 'z1'
genML$VEIN$best.learners$CLAN$z1
plot(genML, type = "CLAN", CLAN.variable = "z1", title = "CLAN of 'z1'")

# > plot(genML, type = "CLAN", CLAN.variable = "z7", title = "CLAN of 'z7'")


# No indication of heterogeneity```
```



## R Markdown

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:

```{r cars}
summary(cars)
```

## Including Plots

You can also embed plots, for example:

```{r pressure, echo=FALSE}
plot(pressure)
```

Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.
